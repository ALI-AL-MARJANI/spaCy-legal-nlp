[paths]
# Training and evaluation data (will be generated later)
train = ${assets}/train.spacy
dev = ${assets}/dev.spacy
vectors = null


[nlp]
# Language and pipeline order , the text goes through these components sequentially
lang = "en"
pipeline = ["tok2vec", "textcat", "ner", "risk_scorer"]
batch_size = 128


[components]
# Tok2Vec: shared feature extractor for the downstream tasks
[components.tok2vec]
factory = "tok2vec"

[components.tok2vec.model]
@architectures = "spacy.Tok2Vec.v2"
width = 256
embed_size = 256
window_size = 1
maxout_pieces = 3
depth = 4


# Text Classification , we identify contract clauses (multi-label)
[components.textcat]
factory = "textcat"
threshold = 0.5   # probabilities above this are considered positive

[components.textcat.model]
@architectures = "spacy.TextCatEnsemble.v2"
width = ${components.tok2vec.model.width}
exclusive_classes = false   # for multi-label classification
nO = null                   # it's defined automatically during training
nI = null


# Named Entity Recognition (NER): extracts legal entities from text
[components.ner]
factory = "ner"

[components.ner.model]
@architectures = "spacy.TransitionBasedParser.v2"
state_type = "ner"
hidden_width = 64
maxout_pieces = 2
use_upper = false
nO = null


# Custom component: risk Scorer , we will implement it manually in the project
[components.risk_scorer]
factory = "risk_scorer"

[components.risk_scorer.model]
@architectures = "spacy.TextCatBOW.v1"
exclusive_classes = false
nO = 1   # outputs a single risk score



# Training settings
[training]
seed = 42
dropout = 0.2
optimizer = { @optimizers = "Adam.v1" }
use_gpu = -1   

[training.optimizer]
learn_rate = 0.001


[training.batcher]
@batchers = "spacy.batch_by_words.v1"
size = 2000
buffer = 256

# Logging settings
[training.logger]
@loggers = "spacy.ConsoleLogger.v1"
